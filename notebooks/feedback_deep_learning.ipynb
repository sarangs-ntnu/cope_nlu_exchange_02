{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning Text Classification with Pretrained Embeddings\n",
    "\n",
    "This notebook extends the feedback classification example with a deep learning workflow that uses modern word embeddings and a multi-task neural model to predict:\n",
    "\n",
    "- Whether a comment refers to a **teacher** or **course**\n",
    "- The **sentiment** of the comment\n",
    "- The **aspect** category (e.g., teaching skills, behaviour, relevancy)\n",
    "\n",
    "It loads the text-based dataset (`data/data_feedback.csv`), optionally recreates an Excel file for compatibility, and trains a BiLSTM classifier using pretrained word vectors when available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Environment and Dependencies\n",
    "\n",
    "This notebook relies on PyTorch and TorchText for sequence modeling. If you want to use pretrained GloVe embeddings, TorchText will attempt to download them the first time they are requested. If the environment lacks internet access, the notebook will transparently fall back to randomly initialized embeddings and note the limitation in the logs.\n",
    "\n",
    "```\n",
    "pip install torch torchtext scikit-learn pandas matplotlib seaborn\n",
    "# Optional for gradient-based explanations\n",
    "pip install captum\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from captum.attr import IntegratedGradients\n",
    "    CAPTUM_AVAILABLE = True\n",
    "except Exception:\n",
    "    CAPTUM_AVAILABLE = False\n",
    "    print(\"Captum is not installed; gradient-based token attributions will be skipped.\")\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, GloVe\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load the Dataset\n",
    "\n",
    "The dataset is stored as a text-based CSV (`data/data_feedback.csv`) to avoid binary artifacts. If you need an Excel version, uncomment the export cell to generate `data/data_feedback.xlsx` dynamically.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = os.path.join('..', 'data', 'data_feedback.csv')\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Uncomment to create an Excel file if you prefer working with XLSX in other tools.\n",
    "# excel_path = os.path.join('..', 'data', 'data_feedback.xlsx')\n",
    "# df.to_excel(excel_path, index=False)\n",
    "# print(f\"Wrote Excel export to {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Label Encoding\n",
    "\n",
    "We will map each target column to integer IDs for modeling. Dictionaries are kept to decode predictions back to readable strings.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "label_columns = ['teacher/course', 'sentiment', 'aspect']\n",
    "label_maps = {}\n",
    "inv_label_maps = {}\n",
    "for col in label_columns:\n",
    "    uniques = sorted(df[col].unique())\n",
    "    label_maps[col] = {label: idx for idx, label in enumerate(uniques)}\n",
    "    inv_label_maps[col] = {v: k for k, v in label_maps[col].items()}\n",
    "\n",
    "encoded_df = df.copy()\n",
    "for col in label_columns:\n",
    "    encoded_df[col] = encoded_df[col].map(label_maps[col])\n",
    "\n",
    "encoded_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Train/Validation Split\n",
    "\n",
    "We create a stratified split on the sentiment column (the most balanced target) to keep distributions reasonable across splits.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    encoded_df,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=encoded_df['sentiment']\n",
    ")\n",
    "\n",
    "len(train_df), len(val_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tokenization and Vocabulary\n",
    "\n",
    "We tokenize using TorchText's `basic_english` tokenizer, build a vocabulary from the training data, and attempt to load pretrained GloVe vectors. If the vectors cannot be downloaded, the notebook falls back to a randomly initialized embedding matrix and logs the limitation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "train_tokens = [tokenizer(text) for text in train_df['comments']]\n",
    "\n",
    "# Build vocabulary with a minimum frequency of 1 due to the small dataset\n",
    "counter = Counter(token for tokens in train_tokens for token in tokens)\n",
    "vocab = Vocab(counter, specials=['<unk>', '<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "# Try to load pretrained vectors\n",
    "embedding_dim = 100\n",
    "vectors = None\n",
    "try:\n",
    "    print(\"Attempting to load GloVe embeddings (6B, 100d)...\")\n",
    "    glove = GloVe(name='6B', dim=embedding_dim)\n",
    "    vectors = glove.get_vecs_by_tokens(vocab.get_itos())\n",
    "    print(\"GloVe embeddings loaded.\")\n",
    "except Exception as exc:\n",
    "    print(f\"Could not load GloVe embeddings: {exc}\\nUsing randomly initialized embeddings instead.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sequence Encoding and DataLoaders\n",
    "\n",
    "We convert tokens to integer IDs, pad batches dynamically, and create PyTorch `DataLoader` objects for training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def encode_text(text: str):\n",
    "    return [vocab[token] for token in tokenizer(text)]\n",
    "\n",
    "\n",
    "class FeedbackDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, frame):\n",
    "        self.comments = frame['comments'].tolist()\n",
    "        self.labels = frame[label_columns].values.astype('int64')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = encode_text(self.comments[idx])\n",
    "        targets = torch.tensor(self.labels[idx])\n",
    "        return torch.tensor(tokens, dtype=torch.long), targets\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    token_lists, targets = zip(*batch)\n",
    "    lengths = torch.tensor([len(tokens) for tokens in token_lists], dtype=torch.long)\n",
    "    padded_tokens = nn.utils.rnn.pad_sequence(token_lists, batch_first=True, padding_value=vocab['<pad>'])\n",
    "    targets = torch.stack(targets)\n",
    "    return padded_tokens, lengths, targets\n",
    "\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "train_dataset = FeedbackDataset(train_df)\n",
    "val_dataset = FeedbackDataset(val_df)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model Definition\n",
    "\n",
    "We use a simple BiLSTM encoder with a shared embedding layer and three classification heads (one per task). The loss is the sum of the cross-entropy losses across heads, encouraging the model to learn a shared representation for all targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "class MultiTaskBiLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers, label_sizes, pad_idx, pretrained_vectors=None, freeze_embeddings=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        if pretrained_vectors is not None:\n",
    "            with torch.no_grad():\n",
    "                self.embedding.weight.data.copy_(pretrained_vectors)\n",
    "            if freeze_embeddings:\n",
    "                self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=embed_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.heads = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim * 2, out_dim) for out_dim in label_sizes\n",
    "        ])\n",
    "\n",
    "    def forward(self, tokens, lengths):\n",
    "        embedded = self.embedding(tokens)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.encoder(packed)\n",
    "        enc_out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)\n",
    "        mask = (tokens != vocab['<pad>']).unsqueeze(-1)\n",
    "        enc_out = enc_out * mask\n",
    "        summed = enc_out.sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1)\n",
    "        pooled = summed / denom\n",
    "        pooled = self.dropout(pooled)\n",
    "        return [head(pooled) for head in self.heads]\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "label_sizes = [len(label_maps[col]) for col in label_columns]\n",
    "\n",
    "pretrained_vectors = vectors if vectors is not None else None\n",
    "model = MultiTaskBiLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=embedding_dim,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    label_sizes=label_sizes,\n",
    "    pad_idx=vocab['<pad>'],\n",
    "    pretrained_vectors=pretrained_vectors,\n",
    "    freeze_embeddings=False,\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training Loop\n",
    "\n",
    "The training step sums the cross-entropy losses for each head. Because the dataset is small, we keep the number of epochs modest; adjust as needed for experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    epoch_loss = 0.0\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    for tokens, lengths, targets in loader:\n",
    "        tokens = tokens.to(DEVICE)\n",
    "        lengths = lengths.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits_list = model(tokens, lengths)\n",
    "        losses = [criterion(logits, targets[:, idx]) for idx, logits in enumerate(logits_list)]\n",
    "        loss = sum(losses)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * tokens.size(0)\n",
    "\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "train_history = []\n",
    "val_history = []\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss = run_epoch(train_loader, train=True)\n",
    "    val_loss = run_epoch(val_loader, train=False)\n",
    "    train_history.append(train_loss)\n",
    "    val_history.append(val_loss)\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:02d}: train_loss={train_loss:.4f} val_loss={val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loss Curves\n",
    "\n",
    "Plot the training and validation loss to see if the model is converging.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_history, label='train')\n",
    "plt.plot(val_history, label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluation\n",
    "\n",
    "We compute accuracy per task on the validation split and show confusion matrices to highlight common confusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "    all_targets = [[] for _ in label_columns]\n",
    "    all_preds = [[] for _ in label_columns]\n",
    "    with torch.no_grad():\n",
    "        for tokens, lengths, targets in loader:\n",
    "            tokens = tokens.to(DEVICE)\n",
    "            lengths = lengths.to(DEVICE)\n",
    "            logits_list = model(tokens, lengths)\n",
    "            for idx, logits in enumerate(logits_list):\n",
    "                preds = logits.argmax(dim=1).cpu().tolist()\n",
    "                all_preds[idx].extend(preds)\n",
    "                all_targets[idx].extend(targets[:, idx].tolist())\n",
    "    return all_targets, all_preds\n",
    "\n",
    "\n",
    "targets, preds = predict(val_loader)\n",
    "\n",
    "for i, col in enumerate(label_columns):\n",
    "    acc = accuracy_score(targets[i], preds[i])\n",
    "    print(f\"{col} accuracy: {acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, col in enumerate(label_columns):\n",
    "    cm = confusion_matrix(targets[i], preds[i], labels=list(range(len(label_maps[col]))))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i])\n",
    "    axes[i].set_title(f\"Confusion Matrix: {col}\")\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('True')\n",
    "    axes[i].set_xticklabels(label_maps[col].keys(), rotation=45)\n",
    "    axes[i].set_yticklabels(label_maps[col].keys(), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inspect Misclassifications\n",
    "\n",
    "To better understand errors, list examples where predictions differ from the ground truth for each head.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "val_df_with_preds = val_df.copy().reset_index(drop=True)\n",
    "for i, col in enumerate(label_columns):\n",
    "    val_df_with_preds[f\"pred_{col}\"] = preds[i]\n",
    "    val_df_with_preds[f\"pred_{col}_label\"] = val_df_with_preds[f\"pred_{col}\"].map(inv_label_maps[col])\n",
    "    val_df_with_preds[f\"true_{col}_label\"] = val_df_with_preds[col].map(inv_label_maps[col])\n",
    "\n",
    "for col in label_columns:\n",
    "    mismatches = val_df_with_preds[val_df_with_preds[col] != val_df_with_preds[f\"pred_{col}\"]]\n",
    "    display_cols = ['comments', f\"true_{col}_label\", f\"pred_{col}_label\"]\n",
    "    print(f\"\\nMisclassifications for {col} (showing up to 5):\")\n",
    "    display(mismatches[display_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Explainability (Optional)\n",
    "\n",
    "If Captum is installed, we can compute Integrated Gradients over tokens for a sample prediction to highlight which words influenced the teacher/course decision. This provides qualitative insight into what the model is focusing on.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if CAPTUM_AVAILABLE:\n",
    "    sample_text = val_df.iloc[0]['comments']\n",
    "    token_ids = torch.tensor([encode_text(sample_text)], dtype=torch.long)\n",
    "    lengths = torch.tensor([len(token_ids[0])], dtype=torch.long)\n",
    "\n",
    "    def forward_teacher(input_tokens, input_lengths):\n",
    "        logits_list = model(input_tokens.to(DEVICE), input_lengths.to(DEVICE))\n",
    "        return logits_list[0]\n",
    "\n",
    "    ig = IntegratedGradients(forward_teacher)\n",
    "\n",
    "    model.eval()\n",
    "    attributions, _ = ig.attribute(\n",
    "        inputs=token_ids.to(DEVICE),\n",
    "        baselines=torch.zeros_like(token_ids).to(DEVICE),\n",
    "        additional_forward_args=lengths.to(DEVICE),\n",
    "        target=val_df.iloc[0]['teacher/course'],\n",
    "        return_convergence_delta=True,\n",
    "    )\n",
    "\n",
    "    token_list = tokenizer(sample_text)\n",
    "    token_attr = attributions.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
    "    token_attr = token_attr / (np.abs(token_attr).max() + 1e-8)\n",
    "\n",
    "    print(f\"Text: {sample_text}\")\n",
    "    for token, score in zip(token_list, token_attr):\n",
    "        print(f\"{token:15s} -> {score:+.3f}\")\n",
    "else:\n",
    "    print(\"Captum not available; install captum to run Integrated Gradients.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}